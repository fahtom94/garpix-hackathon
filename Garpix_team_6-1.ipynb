{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5416f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b51849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pprint import pprint \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "  Args:\n",
    "    dir_path (str or pathlib.Path): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} JSON files in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"ALGORITM/\")\n",
    "walk_through_dir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all file paths - все файлы в папке ALGORITM\n",
    "file_path_list = list(data_path.glob(\"*.json\"))\n",
    "\n",
    "i = 0\n",
    "file_id=list()\n",
    "print(type(file_id))\n",
    "for file in file_path_list: \n",
    "   \n",
    "    print(f\"{i+1} file path: {file_path_list[i]}\")\n",
    "    fp = str(file_path_list[i])\n",
    "    file_id.append(fp[-10:-5])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467f70b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = 0\n",
    "load_data = pd.DataFrame()\n",
    "ld = pd.DataFrame()\n",
    "for file in file_path_list: \n",
    "    file_path = 'ALGORITM/data_for_algoritm_' + file_id[k] + '.json'\n",
    "    load_file = 'da_'+ file_id[k]\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        load_file = json.load(f) \n",
    "    df2 = pd.json_normalize(load_file, max_level=3).melt()\n",
    "    \n",
    " # вывод таблиц с размерами и свойствами коробок, а их дофига...\n",
    "    df4 = pd.json_normalize(df2.loc[df2[\"variable\"] == \"data_result.boxes\",\"value\"].iloc[0], max_level=0).melt()\n",
    "    cargo = pd.DataFrame()\n",
    "    cargo['size'] = df4.loc[df4['variable'] == 'size', ['value']].reset_index(drop=True)\n",
    "    stacking = df4.loc[df4['variable'] == 'stacking', ['value']].reset_index(drop=True)\n",
    "    turnover = df4.loc[df4['variable'] == 'turnover', ['value']].reset_index(drop=True)\n",
    "    cargo['turnover'] = turnover['value']\n",
    "    cargo['stacking'] = stacking['value'] \n",
    "    #display(cargo)  # для вывода всех таблиц с размерами и свойствами коробок разкомментируйте эту строку\n",
    "\n",
    " # создание таблицы свойств карго со всех файлов  \n",
    "    load_data = [{'load_id':file_id[k],'density_percent':df2.loc[df2[\"variable\"] == \"data_result.cargo_space.calculation_info.density_percent\",\"value\"].iloc[0], \n",
    "                 'filling_space_percent':df2.loc[df2[\"variable\"] == \"data_result.cargo_space.calculation_info.filling_space_percent\",\"value\"].iloc[0], \n",
    "                 'loading_width':df2.loc[df2[\"variable\"] == \"data_result.cargo_space.loading_size.width\",\"value\"].iloc[0],\n",
    "                 'loading_height':df2.loc[df2[\"variable\"] == \"data_result.cargo_space.loading_size.height\",\"value\"].iloc[0], \n",
    "                 'loading_length':df2.loc[df2[\"variable\"] == \"data_result.cargo_space.loading_size.length\",\"value\"].iloc[0], 'boxes_qty':len(cargo)}]\n",
    "              \n",
    "    ld = pd.concat((ld, pd.DataFrame(load_data)))\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0b0d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # вывод таблицы свойств карго со всех файлов \n",
    "ld.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524355c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
